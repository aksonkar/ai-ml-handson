{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e081df",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/animeshsonkar/src/all-ai/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from tavily import TavilyClient\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a86ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"YOUR_GOOGLE_AI_API_KEY\")\n",
    "tavily_client = TavilyClient(api_key=\"YOUR_TAVILY_API_KEY\")\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7782d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_the_claim(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Check the claim using the Gemini model and Tavily search.\n",
    "    \n",
    "    Args:\n",
    "        claim (str): The claim to be checked.\n",
    "        \n",
    "    Returns:\n",
    "        str: The result of the fact-checking process.\n",
    "    \"\"\"\n",
    "    # Generate a response from the model\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Combine the results\n",
    "   \n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b24fce",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_response(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a response using the Gemini model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input prompt for the model.\n",
    "        \n",
    "    Returns:\n",
    "        str: The generated response from the model.\n",
    "    \"\"\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22aed5c1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def search_web(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web using Tavily and return the first result.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "        \n",
    "    Returns:\n",
    "        str: The search results as string.\n",
    "    \"\"\"\n",
    "    search_result = tavily_client.search(query, max_results=2)\n",
    "    returned_results = search_result['results'] if 'results' in search_result else []\n",
    "    if not returned_results:\n",
    "        return \"No results found.\"\n",
    "    # Print the search results\n",
    "    print(\"Search Results:\")\n",
    "    print(\"----------------\")\n",
    "    print(f\"Total Results: {len(returned_results)}\")\n",
    "    print(f\"Timestamp: {datetime.now().isoformat()}\")\n",
    "    # convert the results into a readable string format\n",
    "    results_string = \"\\n\".join([f\"Title1: {result['title']} - \\n URL: {result['url']}\\n{result['content']}...\" for result in returned_results])\n",
    "    \n",
    "    # Print each result\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    print(\"----------------\")\n",
    "    print(f\"Total Results: {len(search_result['results'])}\")\n",
    "    print(f\"Timestamp: {datetime.now().isoformat()}\")\n",
    "    # Print each result with title, URL, and content snippet\n",
    "    print(\"Results:\")\n",
    "    for result in search_result['results']:\n",
    "        print(f\"Title: {result['title']}\")\n",
    "        print(f\"URL : {result['url']}\")\n",
    "        print(f\"Content : {result['content'][:100]}...\")\n",
    "        print()\n",
    "    return results_string if results_string else \"No results found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597b04ee",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to check the claim.\"\"\"\n",
    "    claim = \"Is RAG still relevant as of today?.\"\n",
    "    print(\"Gathering evidence for the claim...\")\n",
    "\n",
    "    evidence = search_web(claim); \n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a professional fact-checker. Analayze this claim against the evidence:\n",
    "\n",
    "    CLAIM:{claim}\n",
    "\n",
    "    EVIDENCE:{evidence}\n",
    "\n",
    "    Provide a fact-check analysis with:\n",
    "\n",
    "    1. VERDICT: Choose ONE of these:\n",
    "        -TRUE: Claim is factually accuract\n",
    "        -FALSE: Claim is factually incorrect\n",
    "        -PARTIALLY TRUE: Claim has some triuth but is misleading\n",
    "        -UNVERIFIED: Insufficient evidence to determine accuracy\n",
    "        -OUTDATED: Claim was trye but circumstances have changed\n",
    "\n",
    "    2. CONFIDENCE: High/Medium/Low\n",
    "\n",
    "    3. EXPLANATION: Clear 2-3 lines sentence explanation of your verdict\n",
    "\n",
    "    4. KEY EVIDENCE: Brief summary of the most important evidence\n",
    "\n",
    "    keep it concise and factual\n",
    "    \"\"\"\n",
    "    result = check_the_claim(prompt)\n",
    "    print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b75bc370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering evidence for the claim...\n",
      "Search Results:\n",
      "----------------\n",
      "Total Results: 2\n",
      "Timestamp: 2025-07-06T11:47:47.648701\n",
      "\n",
      "Detailed Results:\n",
      "----------------\n",
      "Total Results: 2\n",
      "Timestamp: 2025-07-06T11:47:47.648733\n",
      "Results:\n",
      "Title: Is RAG Still Relevant with Million-Token LLMs? | Blog - AI Agents List\n",
      "URL : https://aiagentslist.com/blog/is-rag-still-relevant-with-million-tokens-llms\n",
      "Content : RAG remains highly relevant and offers distinct, practical advantages that simply stuffing more data...\n",
      "\n",
      "Title: Is rag still worth looking into? : r/LocalLLM - Reddit\n",
      "URL : https://www.reddit.com/r/LocalLLM/comments/1iwv3ah/is_rag_still_worth_looking_into/\n",
      "Content : While RAG remains valuable in theory, most current implementations (especially the \"build RAG in 1 h...\n",
      "\n",
      "Result: 1.  VERDICT: PARTIALLY TRUE\n",
      "\n",
      "2.  CONFIDENCE: Medium\n",
      "\n",
      "3.  EXPLANATION: While RAG is still generally considered relevant, its practical value and the quality of implementations are debated. The evidence suggests RAG offers unique advantages but faces challenges in current implementations.\n",
      "\n",
      "4.  KEY EVIDENCE: The AI Agents List blog asserts RAG's continued relevance, while the Reddit discussion indicates concerns about the quality of current RAG implementations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # Uncomment the line below to run the main function"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
